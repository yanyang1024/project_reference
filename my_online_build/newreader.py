#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€PDFé˜…è¯»å™¨æ¨¡å—

æœ¬æ¨¡å—æä¾›äº†ä¸€ä¸ªå¢å¼ºçš„PDFé˜…è¯»å™¨ï¼Œæ”¯æŒï¼š
1. æ–‡æœ¬å†…å®¹æå–å’Œå¤„ç†
2. å›¾ç‰‡æå–å’Œæ™ºèƒ½åˆå¹¶
3. å›¾ç‰‡æè¿°è‡ªåŠ¨ç”Ÿæˆ
4. ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å†…å®¹åˆ†æ
5. å¤šæ¨¡æ€å†…å®¹ç´¢å¼•å’Œæ˜ å°„

ä¸»è¦åŠŸèƒ½ï¼š
- åŸºäºPyMuPDFçš„é«˜è´¨é‡PDFè§£æ
- æ™ºèƒ½å›¾ç‰‡æ£€æµ‹å’Œæå–
- ç›¸é‚»å›¾ç‰‡è‡ªåŠ¨åˆå¹¶
- åŸºäºä¸Šä¸‹æ–‡çš„å›¾ç‰‡æè¿°ç”Ÿæˆ
- å®Œæ•´çš„å…ƒæ•°æ®ç®¡ç†
- é”™è¯¯å¤„ç†å’Œæ€§èƒ½ç›‘æ§

æŠ€æœ¯ç‰¹æ€§ï¼š
- æ”¯æŒé«˜DPIå›¾ç‰‡æå–ï¼ˆ300 DPIï¼‰
- æ™ºèƒ½æ–‡æœ¬å—æ£€æµ‹å’Œåˆ†æ
- ä¸Šä¸‹æ–‡çª—å£æå–
- å›¾ç‰‡-æè¿°åŒå‘æ˜ å°„
- è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯è¾“å‡º

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0
æ›´æ–°æ—¶é—´: 2025-01-22
"""

# æ ‡å‡†åº“å¯¼å…¥
import os
import json
import time
import logging
from pathlib import Path
from typing import Optional, Dict, List, Any, Union, Tuple
import traceback

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import fitz  # PyMuPDF - PDFå¤„ç†æ ¸å¿ƒåº“
from PIL import Image  # å›¾ç‰‡å¤„ç†åº“
import requests
from urllib.parse import urljoin

# LazyLLMæ¡†æ¶å¯¼å…¥
import lazyllm
from lazyllm.tools.rag.readers import ReaderBase
from lazyllm.tools.rag import DocNode, DocField, DataType, NodeTransform
from lazyllm.module import OnlineChatModuleBase, OnlineEmbeddingModuleBase

# è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥
try:
    from my_online_build.online_web_deploy import CustomChatModule
    logging.info("æˆåŠŸå¯¼å…¥CustomChatModule")
except ImportError as e:
    logging.error(f"å¯¼å…¥CustomChatModuleå¤±è´¥: {e}")
    # æä¾›å¤‡ç”¨æ–¹æ¡ˆ
    CustomChatModule = None

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multimodal_pdf_reader.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultimodalPDFReader(ReaderBase):
    """
    å¤šæ¨¡æ€PDFé˜…è¯»å™¨ç±»
    
    è¿™æ˜¯ä¸€ä¸ªé«˜çº§PDFé˜…è¯»å™¨ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†æ–‡æœ¬å’Œå›¾ç‰‡å†…å®¹ï¼Œ
    å¹¶ä¸ºå›¾ç‰‡ç”Ÿæˆæ™ºèƒ½æè¿°ã€‚ä¸»è¦ç‰¹æ€§åŒ…æ‹¬ï¼š
    
    1. æ–‡æœ¬æå–ï¼š
       - åŸºäºPyMuPDFçš„é«˜è´¨é‡æ–‡æœ¬æå–
       - ä¿ç•™æ–‡æœ¬å—çš„ä½ç½®ä¿¡æ¯
       - æ”¯æŒå¤æ‚å¸ƒå±€çš„PDFæ–‡æ¡£
    
    2. å›¾ç‰‡å¤„ç†ï¼š
       - é«˜åˆ†è¾¨ç‡å›¾ç‰‡æå–ï¼ˆ300 DPIï¼‰
       - æ™ºèƒ½å›¾ç‰‡åˆå¹¶ç®—æ³•
       - ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å›¾ç‰‡æè¿°ç”Ÿæˆ
       - å®Œæ•´çš„å›¾ç‰‡å…ƒæ•°æ®ç®¡ç†
    
    3. å†…å®¹ç´¢å¼•ï¼š
       - å›¾ç‰‡è·¯å¾„åˆ°æè¿°çš„æ˜ å°„
       - æè¿°åˆ°å›¾ç‰‡è·¯å¾„çš„åå‘æ˜ å°„
       - æ”¯æŒå¿«é€Ÿå†…å®¹æ£€ç´¢
    
    4. é”™è¯¯å¤„ç†ï¼š
       - å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
       - è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•
       - ä¼˜é›…çš„é™çº§å¤„ç†
    
    Attributes:
        image_save_dir (str): å›¾ç‰‡ä¿å­˜ç›®å½•çš„ç»å¯¹è·¯å¾„
        llm: ç”¨äºç”Ÿæˆå›¾ç‰‡æè¿°çš„è¯­è¨€æ¨¡å‹å®ä¾‹
        image_description_map (Dict[str, str]): å›¾ç‰‡è·¯å¾„åˆ°æè¿°çš„æ˜ å°„
        description_image_map (Dict[str, str]): æè¿°åˆ°å›¾ç‰‡è·¯å¾„çš„åå‘æ˜ å°„
        processing_stats (Dict): å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(self, image_save_dir: str = './images', llm: Any = None):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€PDFé˜…è¯»å™¨
        
        Args:
            image_save_dir (str): å›¾ç‰‡ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º'./images'
            llm (Any): ç”¨äºç”Ÿæˆå›¾ç‰‡æè¿°çš„è¯­è¨€æ¨¡å‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
            
        Raises:
            OSError: å½“æ— æ³•åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•æ—¶
            ImportError: å½“æ— æ³•å¯¼å…¥å¿…è¦çš„ä¾èµ–æ—¶
        """
        logger.info("åˆå§‹åŒ–MultimodalPDFReader...")
        super().__init__()
        
        # ç¡®ä¿å›¾ç‰‡ä¿å­˜ç›®å½•å­˜åœ¨
        self.image_save_dir = os.path.abspath(image_save_dir)
        try:
            os.makedirs(self.image_save_dir, exist_ok=True)
            logger.info(f"å›¾ç‰‡ä¿å­˜ç›®å½•å·²åˆ›å»º/ç¡®è®¤: {self.image_save_dir}")
        except OSError as e:
            logger.error(f"åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½•å¤±è´¥: {e}")
            raise OSError(f"æ— æ³•åˆ›å»ºå›¾ç‰‡ä¿å­˜ç›®å½• {self.image_save_dir}: {e}")
        
        # åˆå§‹åŒ–LLM
        if llm is None:
            try:
                if CustomChatModule is not None:
                    self.llm = CustomChatModule(
                        base_url='http://127.0.0.1:11434/api/', 
                        model='gemma3'
                    )
                    logger.info("ä½¿ç”¨é»˜è®¤CustomChatModuleåˆå§‹åŒ–LLM")
                else:
                    logger.warning("CustomChatModuleä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨LLM")
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å¤‡ç”¨LLMçš„åˆå§‹åŒ–é€»è¾‘
                    self.llm = None
            except Exception as e:
                logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
                self.llm = None
        else:
            self.llm = llm
            logger.info("ä½¿ç”¨ç”¨æˆ·æä¾›çš„LLM")
            
        # åˆå§‹åŒ–å›¾ç‰‡ç´¢å¼•æ˜ å°„è¡¨
        self.image_description_map = {}  # å›¾ç‰‡è·¯å¾„ -> æè¿°æ–‡æœ¬
        self.description_image_map = {}  # æè¿°æ–‡æœ¬ -> å›¾ç‰‡è·¯å¾„
        
        # åˆå§‹åŒ–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        self.processing_stats = {
            'total_pages_processed': 0,
            'total_images_extracted': 0,
            'total_images_merged': 0,
            'total_text_blocks_extracted': 0,
            'total_processing_time': 0.0,
            'average_time_per_page': 0.0,
            'description_generation_failures': 0,
            'image_extraction_failures': 0
        }
        
        logger.info("MultimodalPDFReaderåˆå§‹åŒ–å®Œæˆ")
        print(f"âœ… PDFé˜…è¯»å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   ğŸ“ å›¾ç‰‡ä¿å­˜ç›®å½•: {self.image_save_dir}")
        print(f"   ğŸ¤– LLMçŠ¶æ€: {'å·²é…ç½®' if self.llm else 'æœªé…ç½®'}")

    def _load_data(self, file: Path, extra_info: Optional[Dict] = None) -> List[DocNode]:
        """
        ä»PDFæ–‡ä»¶åŠ è½½æ•°æ®å¹¶æå–æ–‡æœ¬å’Œå›¾ç‰‡å†…å®¹
        
        è¿™æ˜¯æ ¸å¿ƒå¤„ç†æ–¹æ³•ï¼Œè´Ÿè´£ï¼š
        1. æ‰“å¼€å’Œè§£æPDFæ–‡æ¡£
        2. é€é¡µæå–æ–‡æœ¬å—å’Œå›¾ç‰‡
        3. ç”Ÿæˆå›¾ç‰‡æè¿°
        4. åˆ›å»ºDocNodeå¯¹è±¡
        5. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            file (Path): PDFæ–‡ä»¶è·¯å¾„
            extra_info (Optional[Dict]): é¢å¤–çš„å…ƒæ•°æ®ä¿¡æ¯
            
        Returns:
            List[DocNode]: åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡æè¿°çš„DocNodeå¯¹è±¡åˆ—è¡¨
            
        Raises:
            FileNotFoundError: å½“PDFæ–‡ä»¶ä¸å­˜åœ¨æ—¶
            fitz.FileDataError: å½“PDFæ–‡ä»¶æŸåæˆ–æ— æ³•è¯»å–æ—¶
            Exception: å…¶ä»–å¤„ç†è¿‡ç¨‹ä¸­çš„å¼‚å¸¸
        """
        logger.info(f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {file}")
        processing_start_time = time.time()
        
        # ç¡®ä¿æ–‡ä»¶è·¯å¾„æ˜¯Pathå¯¹è±¡
        if not isinstance(file, Path):
            file = Path(file)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file.exists():
            error_msg = f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {file}"
            logger.error(error_msg)
            raise FileNotFoundError(error_msg)
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = file.stat().st_size
        file_size_mb = file_size / (1024 * 1024)
        logger.info(f"PDFæ–‡ä»¶ä¿¡æ¯ - å¤§å°: {file_size_mb:.2f} MB")
        print(f"ğŸ“„ å¼€å§‹å¤„ç†PDF: {file.name} ({file_size_mb:.2f} MB)")
        
        # ç¡®ä¿å›¾ç‰‡ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.image_save_dir, exist_ok=True)
        
        try:
            # æ‰“å¼€PDFæ–‡æ¡£
            doc = fitz.open(file)
            logger.info(f"PDFæ–‡æ¡£æ‰“å¼€æˆåŠŸ - æ€»é¡µæ•°: {len(doc)}")
            print(f"   ğŸ“– æ€»é¡µæ•°: {len(doc)}")
            
        except fitz.FileDataError as e:
            error_msg = f"PDFæ–‡ä»¶æŸåæˆ–æ— æ³•è¯»å–: {e}"
            logger.error(error_msg)
            raise fitz.FileDataError(error_msg)
        except Exception as e:
            error_msg = f"æ‰“å¼€PDFæ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        nodes = []
        image_count = 0
        
        try:
            # é€é¡µå¤„ç†PDFå†…å®¹
            for page_index in range(len(doc)):
                page_start_time = time.time()
                logger.info(f"å¤„ç†ç¬¬ {page_index + 1} é¡µ...")
                
                try:
                    page = doc.load_page(page_index)
                    
                    # æå–æ–‡æœ¬å—
                    logger.debug(f"ç¬¬ {page_index + 1} é¡µï¼šå¼€å§‹æå–æ–‡æœ¬å—")
                    text_blocks = self.extract_text_blocks(page)
                    text_block_count = len([b for b in text_blocks if b['content'].strip()])
                    self.processing_stats['total_text_blocks_extracted'] += text_block_count
                    logger.debug(f"ç¬¬ {page_index + 1} é¡µï¼šæå–åˆ° {text_block_count} ä¸ªæ–‡æœ¬å—")
                    
                    # æå–å’Œå¤„ç†å›¾ç‰‡
                    logger.debug(f"ç¬¬ {page_index + 1} é¡µï¼šå¼€å§‹æå–å›¾ç‰‡")
                    page_image_count = self._process_page_images(
                        page, page_index, text_blocks, nodes, image_count, extra_info, file
                    )
                    image_count += page_image_count
                    
                    # æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹
                    text_nodes_added = self._add_text_nodes(
                        text_blocks, page_index, nodes, extra_info, file
                    )
                    
                    page_time = time.time() - page_start_time
                    logger.info(f"ç¬¬ {page_index + 1} é¡µå¤„ç†å®Œæˆ - è€—æ—¶: {page_time:.2f}ç§’, "
                              f"æ–‡æœ¬å—: {text_nodes_added}, å›¾ç‰‡: {page_image_count}")
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    self.processing_stats['total_pages_processed'] += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if (page_index + 1) % 5 == 0 or page_index == len(doc) - 1:
                        progress = ((page_index + 1) / len(doc)) * 100
                        print(f"   ğŸ“Š å¤„ç†è¿›åº¦: {progress:.1f}% ({page_index + 1}/{len(doc)})")
                    
                except Exception as e:
                    logger.error(f"å¤„ç†ç¬¬ {page_index + 1} é¡µæ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    print(f"   âŒ ç¬¬ {page_index + 1} é¡µå¤„ç†å¤±è´¥: {e}")
                    # ç»§ç»­å¤„ç†ä¸‹ä¸€é¡µï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                    continue
            
        finally:
            # ç¡®ä¿æ–‡æ¡£è¢«æ­£ç¡®å…³é—­
            doc.close()
            logger.info("PDFæ–‡æ¡£å·²å…³é—­")
        
        # è®¡ç®—æ€»å¤„ç†æ—¶é—´å’Œç»Ÿè®¡ä¿¡æ¯
        total_time = time.time() - processing_start_time
        self.processing_stats['total_processing_time'] += total_time
        self.processing_stats['total_images_extracted'] = image_count
        
        if self.processing_stats['total_pages_processed'] > 0:
            self.processing_stats['average_time_per_page'] = (
                self.processing_stats['total_processing_time'] / 
                self.processing_stats['total_pages_processed']
            )
        
        # è¾“å‡ºå¤„ç†æ€»ç»“
        logger.info(f"PDFå¤„ç†å®Œæˆ - æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info(f"å¤„ç†ç»Ÿè®¡ - é¡µæ•°: {len(nodes)}, å›¾ç‰‡: {image_count}, "
                   f"æ–‡æœ¬å—: {self.processing_stats['total_text_blocks_extracted']}")
        
        print(f"âœ… PDFå¤„ç†å®Œæˆ")
        print(f"   â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   ğŸ“„ å¤„ç†é¡µæ•°: {self.processing_stats['total_pages_processed']}")
        print(f"   ğŸ–¼ï¸  æå–å›¾ç‰‡: {image_count}å¼ ")
        print(f"   ğŸ“ æ–‡æœ¬å—: {self.processing_stats['total_text_blocks_extracted']}ä¸ª")
        print(f"   ğŸ“Š å¹³å‡æ¯é¡µè€—æ—¶: {self.processing_stats['average_time_per_page']:.2f}ç§’")
        
        return nodes
    
    def _process_page_images(self, page, page_index: int, text_blocks: List[Dict], 
                           nodes: List[DocNode], current_image_count: int, 
                           extra_info: Optional[Dict], file: Path) -> int:
        """
        å¤„ç†å•é¡µçš„å›¾ç‰‡å†…å®¹
        
        Args:
            page: PyMuPDFé¡µé¢å¯¹è±¡
            page_index (int): é¡µé¢ç´¢å¼•
            text_blocks (List[Dict]): æ–‡æœ¬å—åˆ—è¡¨
            nodes (List[DocNode]): èŠ‚ç‚¹åˆ—è¡¨ï¼ˆç”¨äºæ·»åŠ æ–°èŠ‚ç‚¹ï¼‰
            current_image_count (int): å½“å‰å›¾ç‰‡è®¡æ•°
            extra_info (Optional[Dict]): é¢å¤–å…ƒæ•°æ®
            file (Path): PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            int: æœ¬é¡µå¤„ç†çš„å›¾ç‰‡æ•°é‡
        """
        logger.debug(f"å¼€å§‹å¤„ç†ç¬¬ {page_index + 1} é¡µçš„å›¾ç‰‡...")
        page_image_count = 0
        
        try:
            # è®¾ç½®é«˜åˆ†è¾¨ç‡çŸ©é˜µï¼ˆ300 DPIï¼‰
            mat = fitz.Matrix(300/72, 300/72)
            
            # è·å–é¡µé¢å›¾ç‰‡ä¿¡æ¯
            img_infos = page.get_image_info(xrefs=True)
            logger.debug(f"ç¬¬ {page_index + 1} é¡µå‘ç° {len(img_infos)} ä¸ªå›¾ç‰‡å¯¹è±¡")
            
            if not img_infos:
                return 0
            
            # æå–å›¾ç‰‡ä¿¡æ¯
            images = []
            for img_idx, img in enumerate(img_infos):
                try:
                    rect = fitz.Rect(img['bbox'])
                    if rect.is_empty:
                        logger.debug(f"è·³è¿‡ç©ºçŸ©å½¢å›¾ç‰‡ {img_idx + 1}")
                        continue
                    
                    # æå–å›¾ç‰‡åƒç´ æ•°æ®
                    pix = page.get_pixmap(matrix=mat, clip=rect)
                    
                    # æŸ¥æ‰¾ç›¸é‚»æ–‡æœ¬
                    adjacent_texts = self.find_adjacent_text(rect, text_blocks)
                    context_before, context_after = self.extract_context_window(adjacent_texts)
                    
                    images.append({
                        'rect': rect,
                        'pix': pix,
                        'context_before': context_before,
                        'context_after': context_after,
                        'index': img_idx
                    })
                    
                except Exception as e:
                    logger.error(f"æå–ç¬¬ {img_idx + 1} ä¸ªå›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    self.processing_stats['image_extraction_failures'] += 1
                    continue
            
            if not images:
                logger.debug(f"ç¬¬ {page_index + 1} é¡µæ²¡æœ‰æœ‰æ•ˆå›¾ç‰‡")
                return 0
            
            # æŒ‰å‚ç›´ä½ç½®æ’åºå›¾ç‰‡ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
            images.sort(key=lambda x: x['rect'].y0)
            logger.debug(f"ç¬¬ {page_index + 1} é¡µæœ‰æ•ˆå›¾ç‰‡æ•°é‡: {len(images)}")
            
            # å›¾ç‰‡åˆ†ç»„å’Œåˆå¹¶
            groups = self._group_mergeable_images(images)
            logger.debug(f"ç¬¬ {page_index + 1} é¡µå›¾ç‰‡åˆ†ç»„æ•°é‡: {len(groups)}")
            
            # å¤„ç†æ¯ä¸ªå›¾ç‰‡ç»„
            for group_idx, group in enumerate(groups):
                try:
                    if len(group) == 1:
                        # å•ä¸ªå›¾ç‰‡å¤„ç†
                        page_image_count += self._process_single_image(
                            group[0], page_index, current_image_count + page_image_count,
                            nodes, extra_info, file
                        )
                    else:
                        # åˆå¹¶å›¾ç‰‡å¤„ç†
                        page_image_count += self._process_merged_images(
                            group, page_index, current_image_count + page_image_count,
                            nodes, extra_info, file
                        )
                        self.processing_stats['total_images_merged'] += 1
                        
                except Exception as e:
                    logger.error(f"å¤„ç†ç¬¬ {group_idx + 1} ä¸ªå›¾ç‰‡ç»„æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
            
            logger.debug(f"ç¬¬ {page_index + 1} é¡µå›¾ç‰‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {page_image_count} å¼ å›¾ç‰‡")
            
        except Exception as e:
            logger.error(f"å¤„ç†ç¬¬ {page_index + 1} é¡µå›¾ç‰‡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            self.processing_stats['image_extraction_failures'] += 1
        
        return page_image_count
    
    def _group_mergeable_images(self, images: List[Dict]) -> List[List[Dict]]:
        """
        å°†å¯åˆå¹¶çš„å›¾ç‰‡åˆ†ç»„
        
        Args:
            images (List[Dict]): å›¾ç‰‡ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            List[List[Dict]]: å›¾ç‰‡åˆ†ç»„åˆ—è¡¨
        """
        groups = []
        current_group = []
        threshold = 10  # åƒç´ é˜ˆå€¼
        
        for img in images:
            if not current_group:
                current_group.append(img)
            else:
                last = current_group[-1]
                # æ£€æŸ¥å‚ç›´é‡å å’Œæ°´å¹³å¯¹é½
                vertical_overlap = (img['rect'].y0 < last['rect'].y1 + threshold)
                horizontal_overlap = (
                    max(img['rect'].x0, last['rect'].x0) < 
                    min(img['rect'].x1, last['rect'].x1)
                )
                
                if vertical_overlap and horizontal_overlap:
                    current_group.append(img)
                    logger.debug(f"å›¾ç‰‡ {img['index']} ä¸å‰ä¸€å›¾ç‰‡åˆå¹¶")
                else:
                    groups.append(current_group)
                    current_group = [img]
        
        if current_group:
            groups.append(current_group)
        
        return groups
    
    def _process_single_image(self, img: Dict, page_index: int, image_count: int,
                            nodes: List[DocNode], extra_info: Optional[Dict], 
                            file: Path) -> int:
        """
        å¤„ç†å•ä¸ªå›¾ç‰‡
        
        Args:
            img (Dict): å›¾ç‰‡ä¿¡æ¯
            page_index (int): é¡µé¢ç´¢å¼•
            image_count (int): å›¾ç‰‡è®¡æ•°
            nodes (List[DocNode]): èŠ‚ç‚¹åˆ—è¡¨
            extra_info (Optional[Dict]): é¢å¤–å…ƒæ•°æ®
            file (Path): PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            int: å¤„ç†çš„å›¾ç‰‡æ•°é‡ï¼ˆ1æˆ–0ï¼‰
        """
        try:
            # ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶åå’Œè·¯å¾„
            img_filename = f'page{page_index+1}_img{image_count+1}.png'
            img_path = os.path.join(self.image_save_dir, img_filename)
            
            # ä¿å­˜å›¾ç‰‡
            img['pix'].save(img_path)
            logger.debug(f"å›¾ç‰‡å·²ä¿å­˜: {img_path}")
            
            # ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæè¿°
            context_before = img['context_before']
            context_after = img['context_after']
            context = f"{context_before} [IMAGE] {context_after}" if context_before or context_after else "[IMAGE]"
            
            # ç”Ÿæˆå›¾ç‰‡æè¿°
            description = self._generate_image_description(context, "image")
            
            # å¤„ç†è·¯å¾„ä¿¡æ¯
            img_path_abs = os.path.abspath(img_path)
            img_filename = os.path.basename(img_path)
            
            # æ›´æ–°å›¾ç‰‡ç´¢å¼•æ˜ å°„è¡¨
            self.image_description_map[img_path_abs] = description
            self.description_image_map[description] = img_path_abs
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = (extra_info or {}).copy()
            metadata.update({
                'file_name': file.name,
                'page': page_index + 1,
                'bbox': list(img['rect']),
                'image_path': img_path_abs,
                'image_filename': img_filename,
                'image_relative_path': os.path.relpath(img_path_abs, self.image_save_dir),
                'type': 'image_description',
                'original_context_before': context_before,
                'original_context_after': context_after,
                'image_size': f"{img['pix'].width}x{img['pix'].height}",
                'processing_timestamp': time.time()
            })
            
            # åˆ›å»ºå¹¶æ·»åŠ èŠ‚ç‚¹
            nodes.append(DocNode(text=description, metadata=metadata))
            logger.debug(f"å•ä¸ªå›¾ç‰‡èŠ‚ç‚¹å·²åˆ›å»º: {img_filename}")
            
            return 1
            
        except Exception as e:
            logger.error(f"å¤„ç†å•ä¸ªå›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.processing_stats['image_extraction_failures'] += 1
            return 0
    
    def _process_merged_images(self, group: List[Dict], page_index: int, image_count: int,
                             nodes: List[DocNode], extra_info: Optional[Dict], 
                             file: Path) -> int:
        """
        å¤„ç†åˆå¹¶å›¾ç‰‡ç»„
        
        Args:
            group (List[Dict]): å›¾ç‰‡ç»„
            page_index (int): é¡µé¢ç´¢å¼•
            image_count (int): å›¾ç‰‡è®¡æ•°
            nodes (List[DocNode]): èŠ‚ç‚¹åˆ—è¡¨
            extra_info (Optional[Dict]): é¢å¤–å…ƒæ•°æ®
            file (Path): PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            int: å¤„ç†çš„å›¾ç‰‡æ•°é‡ï¼ˆ1æˆ–0ï¼‰
        """
        try:
            # æŒ‰å‚ç›´ä½ç½®æ’åº
            group.sort(key=lambda x: x['rect'].y0)
            
            # è®¡ç®—åˆå¹¶åçš„å°ºå¯¸
            merged_width = max(int(g['rect'].width * (300/72)) for g in group)
            merged_height = sum(int(g['rect'].height * (300/72)) for g in group)
            
            logger.debug(f"åˆå¹¶å›¾ç‰‡å°ºå¯¸: {merged_width}x{merged_height}")
            
            # åˆ›å»ºåˆå¹¶å›¾ç‰‡
            merged_img = Image.new('RGB', (merged_width, merged_height), color='white')
            y_offset = 0
            
            for g in group:
                try:
                    # è½¬æ¢ä¸ºPILå›¾ç‰‡
                    pil_img = Image.frombytes('RGB', (g['pix'].width, g['pix'].height), g['pix'].samples)
                    
                    # è°ƒæ•´å®½åº¦ä»¥åŒ¹é…åˆå¹¶å›¾ç‰‡
                    if pil_img.width != merged_width:
                        pil_img = pil_img.resize((merged_width, pil_img.height), Image.Resampling.LANCZOS)
                    
                    # ç²˜è´´åˆ°åˆå¹¶å›¾ç‰‡
                    merged_img.paste(pil_img, (0, y_offset))
                    y_offset += pil_img.height
                    
                except Exception as e:
                    logger.error(f"åˆå¹¶å›¾ç‰‡ç‰‡æ®µæ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
            
            # ç”Ÿæˆæ–‡ä»¶åå’Œè·¯å¾„
            img_filename = f'page{page_index+1}_merged{image_count+1}.png'
            img_path = os.path.join(self.image_save_dir, img_filename)
            
            # ä¿å­˜åˆå¹¶å›¾ç‰‡
            merged_img.save(img_path, 'PNG', quality=95)
            logger.debug(f"åˆå¹¶å›¾ç‰‡å·²ä¿å­˜: {img_path}")
            
            # åˆå¹¶ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_before = ' '.join(g['context_before'] for g in group if g['context_before'])
            context_after = ' '.join(g['context_after'] for g in group if g['context_after'])
            context = f"{context_before} [MERGED_IMAGE] {context_after}" if context_before or context_after else "[MERGED_IMAGE]"
            
            # ç”Ÿæˆå›¾ç‰‡æè¿°
            description = self._generate_image_description(context, "merged_image")
            
            # å¤„ç†è·¯å¾„ä¿¡æ¯
            img_path_abs = os.path.abspath(img_path)
            
            # æ›´æ–°å›¾ç‰‡ç´¢å¼•æ˜ å°„è¡¨
            self.image_description_map[img_path_abs] = description
            self.description_image_map[description] = img_path_abs
            
            # è®¡ç®—åˆå¹¶åŒºåŸŸçš„è¾¹ç•Œæ¡†
            combined_rect = fitz.Rect(
                min(g['rect'].x0 for g in group),
                group[0]['rect'].y0,
                max(g['rect'].x1 for g in group),
                group[-1]['rect'].y1
            )
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = (extra_info or {}).copy()
            metadata.update({
                'file_name': file.name,
                'page': page_index + 1,
                'bbox': list(combined_rect),
                'image_path': img_path_abs,
                'image_filename': img_filename,
                'image_relative_path': os.path.relpath(img_path_abs, self.image_save_dir),
                'type': 'image_description',
                'original_context_before': context_before,
                'original_context_after': context_after,
                'image_size': f"{merged_width}x{merged_height}",
                'merged_count': len(group),
                'processing_timestamp': time.time()
            })
            
            # åˆ›å»ºå¹¶æ·»åŠ èŠ‚ç‚¹
            nodes.append(DocNode(text=description, metadata=metadata))
            logger.debug(f"åˆå¹¶å›¾ç‰‡èŠ‚ç‚¹å·²åˆ›å»º: {img_filename} (åˆå¹¶äº†{len(group)}å¼ å›¾ç‰‡)")
            
            return 1
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆå¹¶å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.processing_stats['image_extraction_failures'] += 1
            return 0
    
    def _generate_image_description(self, context: str, image_type: str) -> str:
        """
        ç”Ÿæˆå›¾ç‰‡æè¿°
        
        Args:
            context (str): å›¾ç‰‡ä¸Šä¸‹æ–‡
            image_type (str): å›¾ç‰‡ç±»å‹ï¼ˆ"image" æˆ– "merged_image"ï¼‰
            
        Returns:
            str: å›¾ç‰‡æè¿°æ–‡æœ¬
        """
        try:
            if self.llm is None:
                logger.warning("LLMæœªé…ç½®ï¼Œä½¿ç”¨é»˜è®¤æè¿°")
                return f"å›¾ç‰‡æè¿°ç”Ÿæˆå™¨æœªé…ç½®ï¼Œä¸Šä¸‹æ–‡ï¼š{context}"
            
            # æ„å»ºæç¤ºè¯
            if image_type == "merged_image":
                prompt = f"Based on the following context, generate a concise description of the merged image: {context}"
            else:
                prompt = f"Based on the following context, generate a concise description of the image: {context}"
            
            logger.debug(f"ç”Ÿæˆå›¾ç‰‡æè¿°ï¼Œæç¤ºè¯é•¿åº¦: {len(prompt)}")
            
            # è°ƒç”¨LLMç”Ÿæˆæè¿°
            description = self.llm(prompt)
            
            # éªŒè¯æè¿°è´¨é‡
            if not description or not description.strip():
                logger.warning("LLMè¿”å›ç©ºæè¿°")
                description = f"å›¾ç‰‡æè¿°ç”Ÿæˆå¤±è´¥ï¼Œä¸Šä¸‹æ–‡ï¼š{context}"
            else:
                logger.debug(f"å›¾ç‰‡æè¿°ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(description)}")
            
            return description.strip()
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡æè¿°ç”Ÿæˆæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.processing_stats['description_generation_failures'] += 1
            
            # è¿”å›åŒ…å«é”™è¯¯ä¿¡æ¯çš„æè¿°
            error_description = f"å›¾ç‰‡å¤„ç†é”™è¯¯ï¼š{str(e)}ï¼Œä¸Šä¸‹æ–‡ï¼š{context}"
            return error_description
    
    def _add_text_nodes(self, text_blocks: List[Dict], page_index: int, 
                       nodes: List[DocNode], extra_info: Optional[Dict], 
                       file: Path) -> int:
        """
        æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹
        
        Args:
            text_blocks (List[Dict]): æ–‡æœ¬å—åˆ—è¡¨
            page_index (int): é¡µé¢ç´¢å¼•
            nodes (List[DocNode]): èŠ‚ç‚¹åˆ—è¡¨
            extra_info (Optional[Dict]): é¢å¤–å…ƒæ•°æ®
            file (Path): PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            int: æ·»åŠ çš„æ–‡æœ¬èŠ‚ç‚¹æ•°é‡
        """
        text_nodes_added = 0
        
        for block in text_blocks:
            if block['content'].strip():
                try:
                    # åˆ›å»ºå…ƒæ•°æ®
                    metadata = (extra_info or {}).copy()
                    metadata.update({
                        'file_name': file.name,
                        'page': page_index + 1,
                        'bbox': block['bbox'],
                        'type': 'text',
                        'text_length': len(block['content']),
                        'processing_timestamp': time.time()
                    })
                    
                    # åˆ›å»ºå¹¶æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹
                    nodes.append(DocNode(text=block['content'], metadata=metadata))
                    text_nodes_added += 1
                    
                except Exception as e:
                    logger.error(f"åˆ›å»ºæ–‡æœ¬èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
        
        logger.debug(f"ç¬¬ {page_index + 1} é¡µæ·»åŠ äº† {text_nodes_added} ä¸ªæ–‡æœ¬èŠ‚ç‚¹")
        return text_nodes_added

    def extract_text_blocks(self, page) -> List[Dict]:
        """
        ä»é¡µé¢æå–æ–‡æœ¬å—
        
        ä½¿ç”¨PyMuPDFçš„å­—å…¸æ¨¡å¼æå–æ–‡æœ¬ï¼Œä¿ç•™ä½ç½®å’Œæ ¼å¼ä¿¡æ¯
        
        Args:
            page: PyMuPDFé¡µé¢å¯¹è±¡
            
        Returns:
            List[Dict]: æ–‡æœ¬å—ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
                - type: 'text'
                - bbox: è¾¹ç•Œæ¡†åæ ‡ [x0, y0, x1, y1]
                - content: æ–‡æœ¬å†…å®¹
                - x0, y0, x1, y1: è¾¹ç•Œæ¡†åæ ‡ï¼ˆä¾¿äºè®¿é—®ï¼‰
        """
        logger.debug("å¼€å§‹æå–æ–‡æœ¬å—...")
        text_blocks = []
        
        try:
            # è·å–é¡µé¢æ–‡æœ¬å­—å…¸
            blocks = page.get_text('dict')['blocks']
            
            for block_idx, block in enumerate(blocks):
                try:
                    # åªå¤„ç†åŒ…å«æ–‡æœ¬è¡Œçš„å—
                    if 'lines' in block:
                        bbox = block['bbox']
                        text_content = ''
                        
                        # éå†æ–‡æœ¬è¡Œå’Œè·¨åº¦
                        for line in block['lines']:
                            for span in line['spans']:
                                text_content += span['text']
                            text_content += '\n'
                        
                        # æ¸…ç†æ–‡æœ¬å†…å®¹
                        text_content = text_content.strip()
                        
                        if text_content:  # åªæ·»åŠ éç©ºæ–‡æœ¬å—
                            text_blocks.append({
                                'type': 'text',
                                'bbox': bbox,
                                'content': text_content,
                                'x0': bbox[0], 'y0': bbox[1], 
                                'x1': bbox[2], 'y1': bbox[3],
                                'block_index': block_idx
                            })
                            
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡æœ¬å— {block_idx} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
            
            logger.debug(f"æå–åˆ° {len(text_blocks)} ä¸ªæœ‰æ•ˆæ–‡æœ¬å—")
            
        except Exception as e:
            logger.error(f"æå–æ–‡æœ¬å—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return text_blocks
    
    def calculate_distance(self, bbox1: Tuple[float, float, float, float], 
                          bbox2: Tuple[float, float, float, float]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†ä¹‹é—´çš„è·ç¦»
        
        ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»è®¡ç®—ä¸¤ä¸ªçŸ©å½¢è¾¹ç•Œæ¡†ä¹‹é—´çš„æœ€çŸ­è·ç¦»
        
        Args:
            bbox1: ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡† (x0, y0, x1, y1)
            bbox2: ç¬¬äºŒä¸ªè¾¹ç•Œæ¡† (x0, y0, x1, y1)
            
        Returns:
            float: ä¸¤ä¸ªè¾¹ç•Œæ¡†ä¹‹é—´çš„è·ç¦»ï¼ˆåƒç´ ï¼‰
        """
        x1_min, y1_min, x1_max, y1_max = bbox1
        x2_min, y2_min, x2_max, y2_max = bbox2
        
        # è®¡ç®—æ°´å¹³å’Œå‚ç›´æ–¹å‘çš„è·ç¦»
        dx = max(0, max(x1_min - x2_max, x2_min - x1_max))
        dy = max(0, max(y1_min - y2_max, y2_min - y1_max))
        
        # è¿”å›æ¬§å‡ é‡Œå¾—è·ç¦»
        distance = (dx ** 2 + dy ** 2) ** 0.5
        return distance
    
    def find_adjacent_text(self, img_bbox: Tuple[float, float, float, float], 
                          text_blocks: List[Dict], max_distance: float = 200) -> List[Dict]:
        """
        æŸ¥æ‰¾å›¾ç‰‡é™„è¿‘çš„æ–‡æœ¬å—
        
        Args:
            img_bbox: å›¾ç‰‡è¾¹ç•Œæ¡†
            text_blocks: æ–‡æœ¬å—åˆ—è¡¨
            max_distance: æœ€å¤§æœç´¢è·ç¦»ï¼ˆåƒç´ ï¼‰
            
        Returns:
            List[Dict]: ç›¸é‚»æ–‡æœ¬ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰è·ç¦»æ’åº
        """
        logger.debug(f"æŸ¥æ‰¾å›¾ç‰‡é™„è¿‘çš„æ–‡æœ¬ï¼Œæœ€å¤§è·ç¦»: {max_distance}")
        adjacent_texts = []
        
        for text_block in text_blocks:
            # è·³è¿‡ç©ºæ–‡æœ¬å—
            if not text_block['content'].strip():
                continue
            
            try:
                # è®¡ç®—è·ç¦»
                distance = self.calculate_distance(img_bbox, text_block['bbox'])
                
                if distance <= max_distance:
                    # ç¡®å®šæ–‡æœ¬ç›¸å¯¹äºå›¾ç‰‡çš„ä½ç½®
                    img_center_y = (img_bbox[1] + img_bbox[3]) / 2
                    text_center_y = (text_block['y0'] + text_block['y1']) / 2
                    position = 'below' if text_center_y > img_center_y else 'above'
                    
                    adjacent_texts.append({
                        'text_block': text_block,
                        'distance': distance,
                        'position': position
                    })
                    
            except Exception as e:
                logger.error(f"è®¡ç®—æ–‡æœ¬å—è·ç¦»æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        # æŒ‰è·ç¦»æ’åºï¼Œå–æœ€è¿‘çš„20ä¸ª
        adjacent_texts.sort(key=lambda x: x['distance'])
        result = adjacent_texts[:20]
        
        logger.debug(f"æ‰¾åˆ° {len(result)} ä¸ªç›¸é‚»æ–‡æœ¬å—")
        return result
    
    def extract_context_window(self, adjacent_texts: List[Dict], 
                             context_window_before: int = 100, 
                             context_window_after: int = 100) -> Tuple[str, str]:
        """
        æå–ä¸Šä¸‹æ–‡çª—å£
        
        ä»ç›¸é‚»æ–‡æœ¬ä¸­æå–å›¾ç‰‡å‰åçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            adjacent_texts: ç›¸é‚»æ–‡æœ¬ä¿¡æ¯åˆ—è¡¨
            context_window_before: å›¾ç‰‡å‰ä¸Šä¸‹æ–‡çš„æœ€å¤§å­—ç¬¦æ•°
            context_window_after: å›¾ç‰‡åä¸Šä¸‹æ–‡çš„æœ€å¤§å­—ç¬¦æ•°
            
        Returns:
            Tuple[str, str]: (å‰ç½®ä¸Šä¸‹æ–‡, åç½®ä¸Šä¸‹æ–‡)
        """
        logger.debug(f"æå–ä¸Šä¸‹æ–‡çª—å£ï¼Œå‰ç½®: {context_window_before}, åç½®: {context_window_after}")
        
        context_before = ''
        context_after = ''
        
        try:
            # åˆ†ç¦»å›¾ç‰‡ä¸Šæ–¹å’Œä¸‹æ–¹çš„æ–‡æœ¬
            texts_above = [t for t in adjacent_texts if t['position'] == 'above']
            texts_below = [t for t in adjacent_texts if t['position'] == 'below']
            
            # æå–å›¾ç‰‡å‰çš„ä¸Šä¸‹æ–‡ï¼ˆå›¾ç‰‡ä¸Šæ–¹çš„æ–‡æœ¬ï¼‰
            if texts_above:
                combined = ' '.join(t['text_block']['content'] for t in texts_above)
                if len(combined) > context_window_before:
                    context_before = combined[-context_window_before:]
                else:
                    context_before = combined
            
            # æå–å›¾ç‰‡åçš„ä¸Šä¸‹æ–‡ï¼ˆå›¾ç‰‡ä¸‹æ–¹çš„æ–‡æœ¬ï¼‰
            if texts_below:
                combined = ' '.join(t['text_block']['content'] for t in texts_below)
                if len(combined) > context_window_after:
                    context_after = combined[:context_window_after]
                else:
                    context_after = combined
            
            logger.debug(f"ä¸Šä¸‹æ–‡æå–å®Œæˆï¼Œå‰ç½®é•¿åº¦: {len(context_before)}, åç½®é•¿åº¦: {len(context_after)}")
            
        except Exception as e:
            logger.error(f"æå–ä¸Šä¸‹æ–‡çª—å£æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return context_before.strip(), context_after.strip()
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """
        è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: åŒ…å«å„ç§å¤„ç†ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return self.processing_stats.copy()
    
    def get_image_mappings(self) -> Tuple[Dict[str, str], Dict[str, str]]:
        """
        è·å–å›¾ç‰‡æ˜ å°„è¡¨
        
        Returns:
            Tuple[Dict[str, str], Dict[str, str]]: (å›¾ç‰‡è·¯å¾„->æè¿°æ˜ å°„, æè¿°->å›¾ç‰‡è·¯å¾„æ˜ å°„)
        """
        return self.image_description_map.copy(), self.description_image_map.copy()
    
    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜å’Œä¸´æ—¶æ•°æ®"""
        logger.info("æ¸…ç†MultimodalPDFReaderç¼“å­˜...")
        self.image_description_map.clear()
        self.description_image_map.clear()
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.processing_stats = {
            'total_pages_processed': 0,
            'total_images_extracted': 0,
            'total_images_merged': 0,
            'total_text_blocks_extracted': 0,
            'total_processing_time': 0.0,
            'average_time_per_page': 0.0,
            'description_generation_failures': 0,
            'image_extraction_failures': 0
        }
        
        logger.info("ç¼“å­˜æ¸…ç†å®Œæˆ")
        print("ğŸ§¹ PDFé˜…è¯»å™¨ç¼“å­˜å·²æ¸…ç†")


# æ¨¡å—çº§åˆ«çš„ä¾¿åˆ©å‡½æ•°
def create_multimodal_pdf_reader(image_save_dir: str = './images', 
                                llm: Any = None) -> MultimodalPDFReader:
    """
    åˆ›å»ºå¤šæ¨¡æ€PDFé˜…è¯»å™¨çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        image_save_dir (str): å›¾ç‰‡ä¿å­˜ç›®å½•
        llm (Any): è¯­è¨€æ¨¡å‹å®ä¾‹
        
    Returns:
        MultimodalPDFReader: é…ç½®å¥½çš„PDFé˜…è¯»å™¨å®ä¾‹
    """
    logger.info(f"åˆ›å»ºå¤šæ¨¡æ€PDFé˜…è¯»å™¨ - å›¾ç‰‡ç›®å½•: {image_save_dir}")
    return MultimodalPDFReader(image_save_dir=image_save_dir, llm=llm)


# æ¨¡å—åˆå§‹åŒ–æ—¥å¿—
logger.info("MultimodalPDFReaderæ¨¡å—åŠ è½½å®Œæˆ")
print("ğŸ“š å¤šæ¨¡æ€PDFé˜…è¯»å™¨æ¨¡å—å·²åŠ è½½")